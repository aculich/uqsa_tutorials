{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: A practical introduction to sensitivity analysis -->\n",
    "# A practical introduction to sensitivity analysis\n",
    "<!-- dom:AUTHOR: Leif Rune Hellevik at Department of Structural Engineering, NTNU -->\n",
    "<!-- Author: --> **Leif Rune Hellevik**, Department of Structural Engineering, NTNU\n",
    "\n",
    "Date: **Feb 1, 2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chaospy as cp\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<div id=\"sec:introduction\"></div>\n",
    "\n",
    "This practical introduction to sensitivity analysis is based on the\n",
    "presentation and examples found in [[saltelli_global_2008]](#saltelli_global_2008). To give\n",
    "the reader an even better hands on expericence of the topic, we have\n",
    "integrated the computations in a python notebook format.\n",
    "\n",
    "Many sensitivity anlyses reported in the literature are based on\n",
    "derviatives at set point or point of interest. Indeed such apporaches\n",
    "are based on the fact that the derivative of $\\partial Y_i/\\partial\n",
    "X_j$ of quantity of interest $Y_i$ as a function of an input variable\n",
    "$X_j$ can be thought of as the mathematical definition of the\n",
    "sensitivity of $Y_i$ versus $X_j$.\n",
    "\n",
    "However, what is important to keep in mind is that local derivatives\n",
    "are only informative at the set point in the parameter space at which\n",
    "they are computed, and do not provide information for the rest of the\n",
    "parameter space. Naturally, such a linearization will matter little\n",
    "for linear models, but for general, nonlinear models, care must be\n",
    "taken.  In particular this is important in situations when the input\n",
    "parameters are uncertain.\n",
    "\n",
    "We will therefore make use of methods based on the exploration of the\n",
    "input parameter space by judiciously selecting samples in that space,\n",
    "which will result in more robust an informative sensitivity measures,\n",
    "than what result from a local derivative at the center of the\n",
    "parameter space.\n",
    "\n",
    "However, to introduce the methods of sensitivity analysis, we shall\n",
    "start from derivatices and illustrate them on a very simple linear\n",
    "model.\n",
    "\n",
    "# A simple linear model\n",
    "\n",
    "As an simple linear model example consider:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:linear_model\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = \\sum_{i=1}^{r} \\Omega_i \\, Z_i\n",
    "\\label{eq:linear_model} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the input factors are $\\mathbf{X} = (\\Omega_1, \\Omega_2, \\ldots,\n",
    "\\Omega_r, Z_1, Z_2, \\ldots, Z_r)$. For simplicity we assume that the\n",
    "model output $Y$ of ([eq:linear_model](#eq:linear_model)) is a single variable and\n",
    "that the $\\Omega s$ are fixed coefficients or weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\Omega_1=\\Omega_2=\\ldots=\\text{constant}\n",
    "\\label{_auto1} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, the true factors of ([eq:linear_model](#eq:linear_model)) are just\n",
    "$(Z_1, Z_2, \\ldots, Z_r)$. The individual variables\n",
    "$Z_i$ are taken to normally distributed with mean zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:NZi\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} Z_i \\sim N(0, \\sigma_{Z_i}), \\qquad i=1,2, \\ldots, r\n",
    "\\label{eq:NZi} \\tag{3} \\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the predicted value $Y$ of the model in ([eq:linear_model](#eq:linear_model)) is\n",
    "linear combination of normally distributed factors, it is easy to\n",
    "verify (see exercices in [[saltelli_global_2008]](#saltelli_global_2008)) that $Y$ also will\n",
    "be normally distributed with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:analytic_mean_std\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bar{y} = \\sum_{i=1}^{r} \\Omega_i \\; \\bar{z}_i, \\qquad \\sigma_Y = \\sqrt{\\sum_{i=1}^{r} \\Omega_i^2 \\, \\sigma_{Z_i}^2}\n",
    "\\label{eq:analytic_mean_std} \\tag{4}\t\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we order the factors from the most certain to the less\n",
    "certain, i.e.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    " \\sigma_{Z_1} <  \\sigma_{Z_2} <  \\ldots  <  \\sigma_{Z_r}\n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplots versus derivatives\n",
    "\n",
    "We have implemented the simple linear model in ([eq:linear_model](#eq:linear_model)) in python as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The linear model\n",
    "def linear_model(w,Z,N):\n",
    "    Y=np.zeros(N)\n",
    "    if (w.size>1):\n",
    "        for i in range(len(w)):\n",
    "            Y[:]+=w[i]*Z[i,:] #+ Z[i,:]*Z[i,:]/5\n",
    "    else:\n",
    "        Y=w*Z\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To hold the mean and the standard deviation of all the input factors\n",
    "we use a numpy-array of size $r\\times 2$, with one row per factor,\n",
    "where the first column holds the mean whereas the second column holds\n",
    "the standard deviation. The weights $\\Omega_{1\\ldots r}$ are stored in a numpy-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mean (column 0) and standard deviations (column 1) for each factor z. r factors=nr. rows\n",
    "r=4 # number of factors \n",
    "zm=np.zeros((r,2))\n",
    "zm[0,1]=1\n",
    "zm[1,1]=2\n",
    "zm[2,1]=3\n",
    "zm[3,1]=4\n",
    "\n",
    "# Set the weigth\n",
    "wc=2\n",
    "w=np.ones(r)*wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now perform a Monte Carlo experiment on our model by generating $N$ samples from the distributions of each factor and an input sample is thus produced:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:mc_sample\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{Z} = \\left [\n",
    "\\begin{array}{cccc}\n",
    "Z_{1,1} & Z_{1,2}  & \\ldots & Z_{1,N} \\\\\n",
    "Z_{2,1} & Z_{2,2}  & \\ldots & Z_{2,N}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "Z_{r,1} & Z_{r,2}  & \\ldots & Z_{r,N}\n",
    "\\end{array} \n",
    "\\right ]\n",
    "\\label{eq:mc_sample} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may the compute a value of $Y$ from ([eq:linear_model](#eq:linear_model)) for each\n",
    "column in ([eq:mc_sample](#eq:mc_sample)) to produce a solution vector\n",
    "$\\mathbf{Y}$. Having sampled $N$ values from each input factor we may\n",
    "produce $r$ scatter plots, by projecting in turn the $N$ values of\n",
    "$\\mathbf{Y}$ against the $N$ values of each of the $r$ input factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:mc_solution\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{Y} = \\left [\n",
    "\\begin{array}{c}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_N\n",
    "\\end{array}\n",
    "\\right ]\n",
    "\\label{eq:mc_solution} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genrate distributions for each element in z\n",
    "N=500\n",
    "Z=np.zeros(shape=(r,N))\n",
    "pdf=[]\n",
    "for i, z in enumerate(zm):\n",
    "    pdf.append(cp.Normal(z[0],z[1]))\n",
    "    Z[i,:]=pdf[i].sample(N)\n",
    "\n",
    "Y = linear_model(w,Z,N)\n",
    "\n",
    "# Scatter plots of data for visual inspection of sensitivity \n",
    "plt.figure()\n",
    "for k in range(r):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    plt.plot(Z[k,:],Y[:],'.')\n",
    "    xlbl='Z'+str(k)\n",
    "    plt.xlabel(xlbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the assumption of independent factors $Z_i$, we may sample\n",
    "each $Z_i$ independently from their marginal distributions and store\n",
    "all the samples for all the factors $Z_i$ in the the numpy array\n",
    "'Z[i,:]', where $i$ corresponds to $Z_i$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        pdf.append(pc.Normal(z[0],z[1]))\n",
    "            Z[i,:]=pdf[i].sample(N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatterplots generated by the python code above we\n",
    "intuitively get the impression that $Y$ is more sensitive to $Z_4$\n",
    "than to $Z_3$, and that $Y$ is more sensitive to $Z_3$ than to $Z_3$,\n",
    "and that we may order the factors my influence on $Y$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:scatter_plot_rank\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z_4 > Z_3 > Z_2 > Z_1 \n",
    "\\label{eq:scatter_plot_rank} \\tag{7}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intuitive notion of influence is based on that there is more shape\n",
    "(or better pattern) in the plot for $Z_4$ than for $Z_3$ and likewise.\n",
    "\n",
    "For our simple linear model in ([eq:linear_model](#eq:linear_model)) we are in the\n",
    "fortunate situation that we may compute the local derivatives analyticaly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Sp\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "S_{Z_i}^{p} = \\frac{\\partial Y}{\\partial Z_i} = \\Omega_i\n",
    "\\label{eq:Sp} \\tag{8}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our code example we set all the $\\Omega_i=2$ for $i=1,\\ldots,4$,\n",
    "and according to the local sensitivity meansure $S_{Z_i}^{p}$ in\n",
    "([eq:Sp](#eq:Sp)) all the input factors $Z_i$s are equally important and\n",
    "independent of the variation of each factor. This measure is clearly\n",
    "at odds with the ranking of influence based on the scatterplots in\n",
    "([eq:scatter_plot_rank](#eq:scatter_plot_rank)) and is an indication of the usefullness of\n",
    "scatterplots in sensititivy analysis. However, the bidimensional\n",
    "scatterplots may in some cases be deceiving and lead to type II\n",
    "errors (i.e. failure to identify influential parameters). ref to Saltelli 2004...\n",
    "\n",
    "Most sensitivity measures aim to preserve the rich information\n",
    "provided by the scatterplots in a condensed format. The challenge is\n",
    "how to rank the factors rapidly and automatically without having to\n",
    "inspect many scatterplots in situations with many input\n",
    "factors. Another challenge with scatterplots is that sensitivities for\n",
    "sets cannot be visualized, while luckily compact sensitivity measures may be\n",
    "defined in such cases.\n",
    "\n",
    "# Normalized derivatives and standardized regression coefficients\n",
    "\n",
    "## Normalized derivatives\n",
    "A simple way to improve the derivative sensitivity measure $S_{Z_i}^{p}$ in\n",
    "([eq:Sp](#eq:Sp)) is to scale the input-output variables with their standard deviations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Ss\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "S_{Z_i}^{\\sigma} = \\frac{\\partial Y/\\sigma_Y}{\\partial Z_i/\\sigma_{Z_i}} = \\frac{\\sigma_{Z_i}}{\\sigma_{Y}} \\; \\frac{\\partial Y}{\\partial Z_i}\n",
    "\\label{eq:Ss} \\tag{9}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of our simple linear model ([eq:linear_model](#eq:linear_model)) we get from\n",
    "([eq:Ss](#eq:Ss)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Ss_simple\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left (S_{Z_i}^{\\sigma} \\right)^2 = \\left( \\frac{\\sigma_{Z_i}}{\\sigma_{Y}}\\right)^2 \\; \\left (\\frac{\\partial Y}{\\partial Z_i}\\right)^2 = \\left( \\frac{\\sigma_{Z_i}\\, \\Omega_i}{\\sigma_{Y}}\\right)^2 \\;  \\qquad \\textsf{which may be rearranged to:} \\qquad \\sigma_y^2 \\, (S_{Z_i}^{\\sigma})^2 = \\left ( \\Omega_{i} \\sigma_{Y} \\right )^2\n",
    "\\label{eq:Ss_simple} \\tag{10}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the linearity of our model we previously found  ([eq:analytic_mean_std](#eq:analytic_mean_std)) which also yields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Ss_model_ded\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\sigma_Y^2 = \\sum_{i=1}^{r} \\left(\\Omega_i^2 \\, \\sigma_{Z_i}\\right)^2\n",
    "\\label{eq:Ss_model_ded} \\tag{11}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both ([eq:Ss_model_ded](#eq:Ss_model_ded)) and ([eq:Ss_simple](#eq:Ss_simple)) must hold simultaneously we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Ss1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left (S_{Z_i}^{\\sigma} \\right)^2=1 \n",
    "\\label{eq:Ss1} \\tag{12}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized derivative measure of sensitivity in ([eq:Ss](#eq:Ss)) is\n",
    "more convincing than ([eq:Sp](#eq:Sp)): first, as it involves both the\n",
    "weights $\\Omega_i$ and the factors $Z_i$ in ([eq:linear_model](#eq:linear_model));\n",
    "second as the measures are properly scaled and summarizes to one,\n",
    "which allows for an easy interpretation of the output sensitivity with\n",
    "respect to each of the input factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Theoretical sensitivity indices\n",
    "s_y=np.sqrt(np.sum((w*zm[:,1])**2))\n",
    "print('s_y=',s_y)\n",
    "\n",
    "s=w*zm[:,1]/s_y\n",
    "print('s=',s, ',   norm(s)=',LA.norm(s))\n",
    "print('s^2=',s**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our samples from our samples of the input factors and the\n",
    "subsequent model evaluations, we may estimate the standard deviation\n",
    "of $\\mathbf{Y}$ and compute the relative error with respect to the\n",
    "theoretical value. You may change the number of sample above,\n",
    "i.e. $N$, and see how $N$ influence the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sensitivity indices based on sampled values\n",
    "print('std(Y)=',np.std(Y, 0), '  rel.err=', (np.std(Y, 0)-s_y)/s_y)\n",
    "print(np.mean(Y,0), np.sqrt(np.var(Y,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $N$ is the size of our Monte Carlo experiment, corresponding\n",
    "to the number of times we have evaluated our simple linear model\n",
    "([eq:linear_model](#eq:linear_model)). The evaluation of the model is normally the\n",
    "most computationally expensive part of the analysis, and for that\n",
    "reasons $N$ is referred to as the 'cost' of the analysis.\n",
    "\n",
    "## Linear regression\n",
    "\n",
    "The most popular way of trying to condense the information provided by scatter plots is to try a multiple linear regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:meta_model\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{Y}_j = b_0 + \\sum_{i=1}^{r} b_j \\, Z_{i,j}\n",
    "\\label{eq:meta_model} \\tag{13}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the coefficients $b_0$ and $b_j$ are found my least-square\n",
    "minimization of the squared differences between the predicted\n",
    "hat-values $\\hat{Y}_j$ from the meta-model ([eq:meta_model](#eq:meta_model)) and\n",
    "the actual model output $Y_j$ produced by the Monte-Carlo simulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:lsm\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "SS = \\sum_{j=1}^{N} \\left (Y_j - \\hat{Y}_j \\right)^2  =  \\sum_{j=1}^{N} \\left (Y_j -\\left (b_0 + \\sum_{i=1}^{r} b_j \\, Z_{i,j} \\right ) \\right)^2 \n",
    "\\label{eq:lsm} \\tag{14}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have generated all the $Y_j$s by a linear model\n",
    "([eq:linear_model](#eq:linear_model)), which has been feed with the Monte-Carlo\n",
    "samples ([eq:mc_sample](#eq:mc_sample)), we excpect that a successfull multiple\n",
    "linear regression analysis will rediscover the original linear model,\n",
    "i.e. $\\hat{b}_0 \\cong 0$ and $\\hat{b}_i \\cong \\Omega_i$ for $i=1,\n",
    "\\ldots, r$, where the hats denote estimates and $\\cong$ means the\n",
    "value which the estimate will converge to the the samples size $N$ is\n",
    "large enough.\n",
    "\n",
    "[Statsmodels](http://statsmodels.sourceforge.net/) is a Python\n",
    "module that allows users to explore data, estimate statistical models,\n",
    "perform statistical tests, and multiple regression analysis. An extensive list of descriptive\n",
    "statistics, statistical tests, plotting functions, and result\n",
    "statistics are available for different types of data and each estimator.\n",
    "\n",
    "Below we have illustrated how such a conventional multiple regression analysis may be carried out with the Statmodels module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standard Multivariate Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = sm.OLS(Y, Z.T).fit()\n",
    "w_ols=results.params  #weights from ordinary least squares\n",
    "print(results.summary())\n",
    "print('Regression coefficients',w_ols)\n",
    "print('Rel.error for coefficients:', (w_ols-w)/w)\n",
    "# fig=plt.figure(figsize=(12,8))\n",
    "# fig = sm.graphics.plot_partregress_grid(results, fig=fig)\n",
    "# fig = plt.figure(figsize=(12, 8))\n",
    "# fig = sm.graphics.plot_ccpr_grid(results, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe in the 'coef' column of the summary generated by Statmodels,\n",
    "the values for the coefficients corresponding to $b_i$ in\n",
    "([eq:meta_model](#eq:meta_model)) are listed, we have also computed the relative\n",
    "error of these coefficients with respect to the analytical weights\n",
    "$\\Omega_i$ in ([eq:linear_model](#eq:linear_model)). You may explore how how the\n",
    "relative error changes with the number of samples $N$.\n",
    "\n",
    "\n",
    "However, more widely used than the raw regression coeffients are their\n",
    "normalized equivalents, often referred to as standardized regression\n",
    "coefficients (SRCs): $\\hat{\\beta_i}= \\hat{b}_i\n",
    "\\,\\sigma_{Z_i}/\\sigma_Y$. And for our simple linear model\n",
    "([eq:linear_model](#eq:linear_model)) we will get the following for a large enough\n",
    "$N$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:src\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\beta_i}= \\frac{\\hat{b}_i \\, \\sigma_{Z_i}}{\\sigma_Y} \\cong \\frac{\\Omega_i \\, \\sigma_{Z_i}}{\\sigma_Y} \n",
    "\\label{eq:src} \\tag{15}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which by comparison with our previous expression for the normalized derivatives in ([eq:Ss](#eq:Ss)) we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}_i = S_{Z_i}^{\\sigma} \\qquad \\textsf{for the linear models only}\n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and consequelty we get from ([eq:Ss1](#eq:Ss1)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:sum_beta\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\sum_{i=1}^{r} \\beta_i^2 = 1\n",
    "\\label{eq:sum_beta} \\tag{16}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we state without proof that the standardized regression coeffients (SRCs)\n",
    "may be obtained by an ordinary least squares approach when the\n",
    "variables involved have been [z-score transformed](https://en.wikipedia.org/wiki/Standard_score). The z-score\n",
    "transformation is also commonly referred to as z-values, z-scores,\n",
    "normal scores, and standardized variables, and is obtained by\n",
    "subtraction of the mean and division of the standard deviation.\n",
    "\n",
    "\n",
    "In the code example below we use the z-score transformation from\n",
    "'scipy', and by performing the standard multiple regression on the\n",
    "transformed factors we get the SRCs in the column 'coef'. The SRCs are\n",
    "stored in the 'res_standardize.params' which we assign to 'src', which\n",
    "allows for direct comparison with the previously computed with the clause:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        print('Rel. error SRC', (beta**2-s**2)/s**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may experiment with the number of sample values $N$ to see how it influences the relative error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the variables to obtain standardized regression coefficients (SRC)\n",
    "from scipy.stats.mstats import zscore\n",
    "res_standardize=sm.OLS(zscore(Y), zscore(Z.T)).fit()\n",
    "print(res_standardize.summary() )\n",
    "beta = res_standardize.params\n",
    "print('\\nSRCs:', beta**2)\n",
    "print('Rel. error SRC', (beta**2-s**2)/s**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized derivatives vs SRCs\n",
    "\n",
    "Note that the two sensitivity measures $S_{Z_i}^{\\sigma}$ in\n",
    "([eq:Ss](#eq:Ss)) and $\\beta$ in ([eq:src](#eq:src)) are only equal for\n",
    "linear models.\n",
    "\n",
    "However, the SRCs $\\beta$s, will be more robust and reliable measures\n",
    "of sensitivity for nonlinear models, as the are multidimensionally\n",
    "averaged measures, resulting from an exploration of the entire space\n",
    "of the input factors. The $S_{Z_i}^{\\sigma}$, on the other hand, are\n",
    "computed at the midpoint of the distribution $Z_{i}$, while keeping\n",
    "all the other factors at their respective midpoints.  For small sample\n",
    "sizes $N$ and many input factors $r$, the $\\beta$s will be rather\n",
    "imprecise. Naturally, one cannot expect to explore a high-dimensional\n",
    "input space with only a handfull of samples and statistical\n",
    "significance tests are available (F-statistic, t-values, p-values), so\n",
    "that the analyst is informed about the extent of the problem.\n",
    "\n",
    "Finally, the 'R-squared'-statistic is normally reported:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:R2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " R^2 =  \\sum_{i=1}^{r} \\beta_i^2 \n",
    "\\label{eq:R2} \\tag{17}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and as we have seen from ([eq:Ss1](#eq:Ss1)) $R^2=1$ for linear models. For\n",
    "nonlinear $R^2<1$, and is the $R^2$-value is interpreted as a measure\n",
    "of the fraction of linearity in the nonlinear model. This number\n",
    "$R^2$, which is also referred to as the coefficient of determination,\n",
    "is also equal to the fraction variance in the data $\\mathbf{Y}$, which\n",
    "is explained by the multiple regression model  ([eq:meta_model](#eq:meta_model)).\n",
    "\n",
    "Note that as we for linear models have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    " \\sum_{i=1}^{r} \\hat{\\beta}_i^2 = 1 =  \\sum_{i=1}^{r} \\left ( \\frac{\\hat{b}_i \\, \\sigma_{Z_i}}{\\sigma_Y} \\right)^2\n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and conceqently by multiplication of $\\sigma_Y^{2}$ on both sides we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Var\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{r}  \\frac{\\hat{b}_i \\, \\sigma_{Z_i}}=\\sigma_Y^{2}=V(Y)\n",
    "\\label{eq:Var} \\tag{18}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $V(Y)$ indicates the variance of $Y$. Note that both\n",
    "([eq:Var](#eq:Var)) and ([eq:Ss](#eq:Ss)) are variance decomposition forumulas,\n",
    "i.e. formulas aportion the contribution of each factor $Z_i$ to the\n",
    "variance of the model $Y$.\n",
    "\n",
    "What we seek are such variance decomopsition formulas for general,\n",
    "nonlinear models, i.e. when $R^2$ is low. One such 'model free'\n",
    "sensitivity measure is based on averaged partial variances, which we\n",
    "will describe below.\n",
    "\n",
    "# Polynomial chaos expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polychaos computations\n",
    "Npc=80\n",
    "jpdf = cp.J(cp.Normal(zm[0,0],zm[0,1]),cp.Normal(zm[1,0],zm[1,1]),cp.Normal(zm[2,0],zm[2,1]),cp.Normal(zm[3,0],zm[3,1]))\n",
    "Zpc=jpdf.sample(Npc)\n",
    "Ypc=linear_model(w, Zpc, Npc)\n",
    "Npol=4\n",
    "poly = cp.orth_chol(Npol, jpdf)\n",
    "approx = cp.fit_regression(poly, Zpc, Ypc, rule=\"T\")\n",
    "\n",
    "print('Expected value from cp=', cp.E(approx,jpdf), '   std=',cp.Std(approx,jpdf))\n",
    "s_pc= cp.Sens_m(approx,jpdf)\n",
    "print('Sensitivity indices from polychaos', s_pc)\n",
    "print('rel err', (s_pc-s**2)/s**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polychaos convergence\n",
    "Npc_list=np.logspace(1,3,10).astype(int)\n",
    "error=[]\n",
    " \n",
    "for i,Npc in enumerate(Npc_list):\n",
    "    Zpc=jpdf.sample(Npc)\n",
    "    Ypc=linear_model(w, Zpc, Npc)\n",
    "    Npol=4\n",
    "    poly = cp.orth_chol(Npol, jpdf)\n",
    "    approx = cp.fit_regression(poly, Zpc, Ypc, rule=\"T\")\n",
    "    s_pc= cp.Sens_m(approx,jpdf)\n",
    "    error.append(LA.norm((s_pc-s**2)/s**2))\n",
    " \n",
    "plt.figure()\n",
    "plt.semilogy(Npc_list,error);\n",
    "plt.xlabel('Nr samples');\n",
    "plt.ylabel('L2-norm of error in Sobol indices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional variances\n",
    "\n",
    "As noted previously, the importance of a factor $Z_i$ is manifested\n",
    "the existence of a 'shape' or 'pattern' in the model outputs\n",
    "$Y$. Conversely, a uniform cloud of output points $Y$ as a function of\n",
    "$Z_i$ is a symptom, albeit not a proof, indicating that $Z_i$ is a\n",
    "noninfluential factor. In this section we seek to demonstrate that\n",
    "conditional variances is a usefull means to quantify the 'shape' or\n",
    "'pattern' in the outputs.\n",
    "\n",
    "The shape in the outputs $Y$ for a given $Z_i$, may be seen in the\n",
    "scatterplot as of $Y$ versus $Z_i$. In particular, we may cut the\n",
    "$Z_i$-axis into slices and assess how the distribution of the outputs\n",
    "$Y$ changes from slice to slice. This is illustrated in the code\n",
    "snippet below, where the slices are identified with vertical dashed\n",
    "lines at equidistant locations on each $Z_i$-axis, $i=1, \\ldots,4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter plots of data, z-slices, and linear model \n",
    "plt.figure()\n",
    "\n",
    "Ndz=10  #Number of slices of the Z-axes\n",
    "\n",
    "Zslice = np.zeros((r,Ndz))   # array for mean-values in the slices\n",
    "ZBndry = np.zeros((r,Ndz+1)) # array for boundaries of the slices\n",
    "dz=np.zeros(r)\n",
    "\n",
    "for k in range(r):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    \n",
    "    zmin=np.min(Z[k,:]); zmax=np.max(Z[k,:]) # each Z[k,:] may have different extremas\n",
    "    dz[k] = (zmax-zmin )/Ndz\n",
    "    \n",
    "    ZBndry[k,:] = np.linspace(zmin,zmax, Ndz+1)\n",
    "    Zslice[k,:] = np.linspace(zmin+dz[k]/2.,zmax-dz[k]/2., Ndz)\n",
    "    \n",
    "    # Plot the slices\n",
    "    for i in range(Ndz):\n",
    "        plt.axvline(ZBndry[k,i], np.amin(Y), np.amax(Y),linestyle='--', color='.75')\n",
    "        \n",
    "    # Plot the data\n",
    "    plt.plot(Z[k,:],Y[:],'.')\n",
    "    xlbl='Z'+str(k)\n",
    "    plt.xlabel(xlbl)\n",
    "    plt.ylabel('Y')        \n",
    "\n",
    "    Ymodel=linear_model(w[k],Zslice[k,:],Ndz)\n",
    "    \n",
    "    plt.plot(Zslice[k,:],Ymodel)\n",
    "    \n",
    "    ymin=np.amin(Y); ymax=np.amax(Y)\n",
    "    plt.ylim([ymin,ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that average value of $Y$ in a very thin slice, corresponds to keeping $Z_i$ fixed whiel while averaging over all output values of $Y$ due to all-but $Z_i$, which corresponds to the conditional expected value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "E_{Z_{\\sim i}} (Y\\;|\\;Z_i) \n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we denote 'all-but $Z_i$' by $Z_{\\sim\n",
    "i}$. Naturally, a measure of how much $E_{Z_{\\sim i}} (Y\\;|\\;Z_i)$\n",
    "varies in the range of $Z_i$ is given by the conditional variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))\n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, the variance the output $Y$ may be decomposed into:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:VarDecomp\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{V}(Y) = E_{Z_i} ( V_{Z_{\\sim i}} (Y \\; | Z_{i})) + \\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))\n",
    "\\label{eq:VarDecomp} \\tag{19}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large $\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))$ will imply that\n",
    "$Z_i$ is an important factor and is therefore coined the first-order\n",
    "effect of $Z_i$ on $Y$, and its fraction of the total variation of $Y$ is expressed by $S_i$, `the first-order sensitivity index` of $Z_i$ on $Y$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "S_i = \\frac{\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))}{\\text{V}(Y)}\n",
    "\\label{}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By ([eq:VarDecomp](#eq:VarDecomp)), $S_i$ is number always in the range $[0,1]$,\n",
    "and a high value implies an important factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter plots of averaged y-values per slice, with averaged data\n",
    "\n",
    "Zsorted=np.zeros_like(Z)\n",
    "Ysorted=np.zeros_like(Z)\n",
    "YsliceMean=np.zeros((r,Ndz))\n",
    "\n",
    "plt.figure()\n",
    "for k in range(r):\n",
    "    plt.subplot(2,2,k+1)\n",
    "\n",
    "    # sort data\n",
    "    sidx=np.argsort(Z[k,:])\n",
    "    Zsorted[k,:]=Z[k,sidx].copy()   \n",
    "    Ysorted[k,:]=Y[sidx].copy()   \n",
    "    \n",
    "    for i in range(Ndz):\n",
    "        plt.axvline(ZBndry[k,i], np.amin(Y), np.amax(Y),linestyle='--', color='.75')\n",
    "\n",
    "        # find indexes of z-values in the current slice        \n",
    "        zidx_range=np.logical_and(Zsorted[k,:]>=ZBndry[k,i],Zsorted[k,:]<ZBndry[k,i+1])\n",
    "                    \n",
    "        if np.any(zidx_range):    #check if range has elements\n",
    "            YsliceMean[k,i]=np.mean(Ysorted[k,zidx_range])\n",
    "        else:                     #set value to None if noe elements in z-slice\n",
    "            YsliceMean[k,i]=None\n",
    "\n",
    "    plt.plot(Zslice[k,:],YsliceMean[k,:],'.')\n",
    "\n",
    "# # Plot linear model\n",
    "    Nmodel=3\n",
    "    zmin=np.min(Zslice[k,:])\n",
    "    zmax=np.max(Zslice[k,:])\n",
    "    \n",
    "    zvals=np.linspace(zmin,zmax,Nmodel)\n",
    "    Ymodel=linear_model(w[k],zvals,Nmodel)\n",
    "    plt.plot(zvals,Ymodel)\n",
    "    \n",
    "    xlbl='Z'+str(k)\n",
    "    plt.xlabel(xlbl)\n",
    "    \n",
    "    plt.ylim(ymin,ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    " 1. <div id=\"saltelli_global_2008\"></div> **A. (Andrea) Saltelli**. \n",
    "    *Global Sensitivity Analysis : the Primer*,\n",
    "    John Wiley,,\n",
    "    2008."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
